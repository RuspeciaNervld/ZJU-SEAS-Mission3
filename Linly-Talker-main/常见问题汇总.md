# 问题汇总

<details open=True>
<summary>目录</summary>

- [一、下载问题](#%E4%B8%80%E4%B8%8B%E8%BD%BD%E9%97%AE%E9%A2%98)
    - [1.1 代码下载](#11-%E4%BB%A3%E7%A0%81%E4%B8%8B%E8%BD%BD)
    - [1.2 权重下载](#12-%E6%9D%83%E9%87%8D%E4%B8%8B%E8%BD%BD)
    - [1.3 网络下载](#13-%E7%BD%91%E7%BB%9C%E4%B8%8B%E8%BD%BD)
    - [1.4 克隆语音 权重](#14-%E5%85%8B%E9%9A%86%E8%AF%AD%E9%9F%B3-%E6%9D%83%E9%87%8D)
- [二、环境配置问题](#%E4%BA%8C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98)
    - [2.1 GPU环境](#21-gpu%E7%8E%AF%E5%A2%83)
    - [2.2 CPU环境](#22-cpu%E7%8E%AF%E5%A2%83)
    - [2.3 显存问题](#23-%E6%98%BE%E5%AD%98%E9%97%AE%E9%A2%98)
- [三、运行问题](#%E4%B8%89%E8%BF%90%E8%A1%8C%E9%97%AE%E9%A2%98)
    - [3.1 文件找不到](#31-%E6%96%87%E4%BB%B6%E6%89%BE%E4%B8%8D%E5%88%B0)
    - [3.2 FFMPEG问题](#32-ffmpeg%E9%97%AE%E9%A2%98)
    - [3.3 路径问题](#33-%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98)
    - [3.4 GFPGANer is not defined](#34-gfpganer-is-not-defined)
    - [3.5 Microsoft Visual C++ 14.0 is required](#35-microsoft-visual-c-140-is-required)
    - [3.6 多个服务器部署](#36-%E5%A4%9A%E4%B8%AA%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2)
    - [3.7 GeminiPro的参数proxy代理设置](#37-geminipro%E7%9A%84%E5%8F%82%E6%95%B0proxy%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE)
    - [3.8 项目更新方向](#38-%E9%A1%B9%E7%9B%AE%E6%9B%B4%E6%96%B0%E6%96%B9%E5%90%91)
    - [3.9 version GLIBCXX_3.4.* not found](#39-version-glibcxx_34-not-found)
    - [3.10 Gradio Connection errored out](#310-gradio-connection-errored-out)
    - [3.11 gr.Error"无克隆环境或者无克隆模型权重，无法克隆声音", e](#311-grerror%E6%97%A0%E5%85%8B%E9%9A%86%E7%8E%AF%E5%A2%83%E6%88%96%E8%80%85%E6%97%A0%E5%85%8B%E9%9A%86%E6%A8%A1%E5%9E%8B%E6%9D%83%E9%87%8D%E6%97%A0%E6%B3%95%E5%85%8B%E9%9A%86%E5%A3%B0%E9%9F%B3-e)
    - [3.12 OSError: [WinError 127] 找不到指定的程序](#312-oserror-winerror-127-%E6%89%BE%E4%B8%8D%E5%88%B0%E6%8C%87%E5%AE%9A%E7%9A%84%E7%A8%8B%E5%BA%8F)
    - [3.13 LLM对话步骤出现错误：“对不起，你的请求出错了，请再次尝试。”](#313-llm%E5%AF%B9%E8%AF%9D%E6%AD%A5%E9%AA%A4%E5%87%BA%E7%8E%B0%E9%94%99%E8%AF%AF%E5%AF%B9%E4%B8%8D%E8%B5%B7%E4%BD%A0%E7%9A%84%E8%AF%B7%E6%B1%82%E5%87%BA%E9%94%99%E4%BA%86%E8%AF%B7%E5%86%8D%E6%AC%A1%E5%B0%9D%E8%AF%95)
- [四、功能迭代问题](#%E5%9B%9B%E5%8A%9F%E8%83%BD%E8%BF%AD%E4%BB%A3%E9%97%AE%E9%A2%98)
    - [4.1 LLM大模型更新](#41-llm%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9B%B4%E6%96%B0)
    - [4.2 克隆语音模型替换](#42-%E5%85%8B%E9%9A%86%E8%AF%AD%E9%9F%B3%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2)
- [五、交流群问题](#%E4%BA%94%E4%BA%A4%E6%B5%81%E7%BE%A4%E9%97%AE%E9%A2%98)

</details>

## 一、下载问题

### 1.1 代码下载

代码可以从Github下载 [https://github.com/Kedreamix/Linly-Talker](https://github.com/Kedreamix/Linly-Talker)，也可以从Gitee下载 [https://gitee.com/kedreamix/Linly-Talker](https://gitee.com/kedreamix/Linly-Talker)



### 1.2 权重下载

SadTalker的代码可以从 [Baidu (百度云盘)](https://pan.baidu.com/s/1eF13O-8wyw4B3MtesctQyg?pwd=linl) (Password: `linl`) 下载，也可以直接运行shell文件`bash scripts/sadtalker_download_models.sh  `运行自动下载（比较适用于Linux）。

Wav2Lip的代码模型也可以从One Drive下载，可以只下载第一个或者第二个：

| Model                        | Description                                           | Link to the model                                            |
| ---------------------------- | ----------------------------------------------------- | ------------------------------------------------------------ |
| Wav2Lip                      | Highly accurate lip-sync                              | [Link](https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/Eb3LEzbfuKlJiR600lQWRxgBIY27JZg80f7V9jtMfbNDaQ?e=TBFBVW) |
| Wav2Lip + GAN                | Slightly inferior lip-sync, but better visual quality | [Link](https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA?e=n9ljGW) |
| Expert Discriminator         | Weights of the expert discriminator                   | [Link](https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/EQRvmiZg-HRAjvI6zqN9eTEBP74KefynCwPWVmF57l-AYA?e=ZRPHKP) |
| Visual Quality Discriminator | Weights of the visual disc trained in a GAN setup     | [Link](https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/EQVqH88dTm1HjlK11eNba5gBbn15WMS0B0EZbDBttqrqkg?e=ic0ljo) |

GPT-SoVITS的代码模型可以从以下链接下载，具体可看[https://github.com/RVC-Boss/GPT-SoVITS/blob/main/docs/cn/README.md#预训练模型](https://github.com/RVC-Boss/GPT-SoVITS/blob/main/docs/cn/README.md#预训练模型)

从 [GPT-SoVITS Models](https://huggingface.co/lj1995/GPT-SoVITS) 下载预训练模型，并将它们放置在 `GPT_SoVITS\pretrained_models` 中。

中国地区用户可以进入以下链接并点击“下载副本”下载以上两个模型：

- [GPT-SoVITS Models](https://www.icloud.com.cn/iclouddrive/056y_Xog_HXpALuVUjscIwTtg#GPT-SoVITS_Models)




### 1.3 网络下载

有时候利用代码下载的时候出现网络问题，可能会有网络的问题，比如大模型的`huggingface`下载，我目前已经加上了[Baidu (百度云盘)](https://pan.baidu.com/s/1eF13O-8wyw4B3MtesctQyg?pwd=linl) (Password: `linl`) ，可以考虑下载到本地以后根据文件夹放置，也可以完成对应的功能。

> 如果有什么文件下载有问题，也可以提建议给我，我会上传到百度网盘。



### 1.4 克隆语音 权重

为了保护用户隐私安全，我并未提供克隆语音的权重，因为这可能涉及版权问题，如果大家感兴趣的话，可以尝试使用相同的方法进行训练或者私聊我，感谢大家的理解



## 二、环境配置问题

### 2.1 GPU环境

我使用的是Pytorch 1.12的版本，由于Pytorch大部份是兼容的，所以我建议是使用>=  1.12的版本来进行下载，具体下载的命令可以根据pytorch官网的命令进行设置 [https://pytorch.org/get-started/previous-versions/](https://pytorch.org/get-started/previous-versions/)，建议有时候可以使用anaconda来安装，这样方便管理和安装其他都比较方便

```bash
conda create -n linly python=3.9 
conda activate linly

# pytorch安装方式1：conda安装（推荐）
conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch

# pytorch安装方式2：pip 安装
pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113

conda install -q ffmpeg # ffmpeg==4.2.2

pip install -r requirements_app.txt
```

> GPU环境有时候需要配置CUDA，这一部分网上有很多介绍，所以这里我就不多说了。



### 2.2 CPU环境

可以将GPU替换为CPU，但是这样可能会比较慢，只需要安装pytorch的时候，不安装GPU版本即可，应该也能完成对应的结果，但是可能结果会比较差，因为需要跑大模型等等，所以还是建议GPU环境



### 2.3 显存问题

暂时以我测试的来说，现在Sadtalker大概默认`Batch Size = 1`，大模型`Qwen 1.8B`大概占 2G 显存，数字人模型`SadTalker`占大概4～6G，所以大概最低为6～8G显存的电脑都能正常部署，这里面针对的是GPU的环境。

建议如果在6G或者更低显存的电脑上运行的时候，可以考虑使用GeminiPro和OpenAI的API，这样可以不用在本地部署对应的大模型，可以较好的节省GPU显存



## 三、运行问题

### 3.1 文件找不到

如果出现`FileNotFound`的问题，如果是权重的问题的话，那就回到1.2的问题，重新下载即可，记住看文件夹结构。



### 3.2 FFMPEG问题

如果正常运行在最后的生成视频出现`ffmpeg`的问题，那可能安装`ffmpeg`出错了，有两种方式。

第一种是使用conda安装`ffmpeg`，需要ffmpeg>=4.2.2左右

```bash
conda install -q ffmpeg # ffmpeg==4.2.2
```

第二种就是正常安装`ffmpeg`

```bash
# Linux下载
sudo apt install ffmpeg
```

第三种就是Windows安装`ffmpeg`

Windows安装下载ffmpeg也是很简单的，我这里给一个链接，大家可以试一下 [Windows下安装使用ffmpeg](https://zhuanlan.zhihu.com/p/118362010)，直接去官网下载即可[https://ffmpeg.org/](https://ffmpeg.org/)。



### 3.3 路径问题

如果下载的时候没有放对位置，需要在`config.py`设置对应的路径，并且可以修改端口的，默认设置为7860，也可以设置其他的端口，只要不被占用即可。



### 3.4 GFPGANer is not defined

如果在运行的时候出现了这个问题，这是一个增强的模块，这一部分模块如果需要运行，首先要安装`gfpgan`库即可

```bash
pip install gfpgan
```



### 3.5 Microsoft Visual C++ 14.0 is required

如果遇到这个问题，是因为window需要一些依赖，可以参考这篇文章解决一下 [Microsoft Visual C++ 14.0 is required解决方法](https://zhuanlan.zhihu.com/p/126669852)

![](https://picx.zhimg.com/80/v2-d25b289827fc989f419df70f650b44e9.png)



### 3.6 多个服务器部署

如果有多台服务器，大模型可以考虑放在另一个服务器中进行部署，我写了FastAPI的版本，可以利用部署api的方式来使用模型。

也可以其实先在本地部署，这样每次运行的时候不用一只load大模型，这样也会等待一段时间。



### 3.7 GeminiPro的参数proxy代理设置

对于GeminiPro的代理设置`proxy_url`可以传入参数，这个参数我设置是`http://127.0.0.1:7890`。

因为我用的是clash，所以开的端口是7890，这里面也可以换成自己对应的端口进行设置。



### 3.8 项目更新方向

如果要加入其他的模型的话和方向的话，可以在对应的文件夹`ASR`，`TTS`，`THG`和`LLM`中添加对应的算法，也可以向我提建议，我有时间也会进行更新的，欢迎大家向我提供资料。

> 我会一直保持更新的哈哈，有时候可能要想一些点子做好一点在放上去，也欢迎大家给我提PR，我都会加油的！！！冲冲冲！！！



### 3.9 version GLIBCXX_3.4.* not found

如果有遇到这样的问题，那可能是一些库的版本的问题，具体可以看，["`GLIBCXX_3.4.32' not found" error at runtime. GCC 13.2.0](https://stackoverflow.com/questions/76974555/glibcxx-3-4-32-not-found-error-at-runtime-gcc-13-2-0)

```bash
/lib/libstdc++.so.6: version `GLIBCXX_3.4.32' not found
```

我这里说一下我发现的问题，大概我发现有两种方式，第一种就是似乎python版本会解决问题，我用3.10居然不会出现错误，3.9出现了错误

第二个解决方法我发现，实际上这个错误是在`pyopenjtalk`库的问题，我们可以降低他的版本即可，比如这样的方法

```bash
pip install pyopenjtalk==0.3.1
```

我们也可以看看自己机器本身含有的GLIBCXX的版本

```bash
strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep GLIBCXX
```



### 3.10 Gradio Connection errored out

我还没有遇到这种问题，但是有一些人遇到了，感觉在win上不稳定的多一点，这一部分大家可以提点建议，跟我说一下有没有一些通用的解决方案，因为在网上查找的资料感觉都不是很行



### 3.11 gr.Error("无克隆环境或者无克隆模型权重，无法克隆声音", e) 

这属于功能迭代的问题，也就是克隆环境和克隆模型权重，首先注意按照克隆环境

```bash
pip install VITS/requirements.txt
```

再根据[4.2 克隆语音模型替换](https://github.com/Kedreamix/Linly-Talker/blob/main/常见问题汇总.md#42-克隆语音模型替换)去修改模型权重即可



### 3.12 OSError: [WinError 127] 找不到指定的程序

这个错误通常发生在尝试在 Windows 操作系统上运行一个程序或命令时，但是系统找不到指定的可执行文件。一般来说，就是对应库的安装没安装好，可以建议根据出错的库重新安装一遍即可。



### 3.13 LLM对话步骤出现错误：“对不起，你的请求出错了，请再次尝试。” 

大模型兼容出现错误，重新安装对应的库即可解决

```bash
pip install transformers==4.32.0 accelerate tiktoken einops scipy transformers_stream_generator==0.0.4 peft deepspeed
```



## 四、功能迭代问题

### 4.1 LLM大模型更新

如果要加入新的LLM大模型，可以在LLM文件夹加入选择的大模型

我这里给出一个适用于任何大型语言模型（LLM）的中文类模板。这个模板旨在具有灵活性和易于配置，同时为不同的模型提供一致的交互接口。

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

class LLMTemplate:
    def __init__(self, model_name_or_path, mode='offline'):
        """
        初始化LLM模板

        Args:
            model_name_or_path (str): 模型名称或路径
            mode (str, optional): 模式，'offline'表示离线模式，'api'表示使用API模式。默认为'offline'。
        """
        self.mode = mode
        self.model, self.tokenizer = self.init_model(model_name_or_path)
        self.history = None
    
    def init_model(self, model_name_or_path):
        """
        初始化语言模型

        Args:
            model_name_or_path (str): 模型名称或路径

        Returns:
            model: 加载的语言模型
            tokenizer: 加载的tokenizer
        """
        model = AutoModelForCausalLM.from_pretrained(model_name_or_path, 
                                                     device_map="auto", 
                                                     trust_remote_code=True).eval()
        tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)
        return model, tokenizer   
    
    def generate(self, prompt, system_prompt=""):
        """
        生成对话响应

        Args:
            prompt (str): 对话的提示
            system_prompt (str, optional): 系统提示。默认为""。

        Returns:
            str: 对话响应
        """
        if self.mode != 'api':
            try:
                response, self.history = self.model.chat(self.tokenizer, prompt, history=self.history, system = system_prompt)
                return response
            except Exception as e:
                print(e)
                return "对不起，你的请求出错了，请再次尝试。\nSorry, your request has encountered an error. Please try again.\n"
        else:
            return self.predict_api(prompt)
    
    def predict_api(self, prompt):
        """
        使用API预测对话响应

        Args:
            prompt (str): 对话的提示

        Returns:
            str: 对话响应
        """
        # 暂时不实现，需要根据具体情况进行实现
        pass 
    
    def chat(self, system_prompt, message):
        """
        进行对话

        Args:
            system_prompt (str): 系统提示
            message (str): 用户消息

        Returns:
            str: 对话响应
        """
        response = self.generate(message, system_prompt)
        self.history.append((message, response))
        return response, self.history
    
    def clear_history(self):
        """
        清空对话历史记录
        """
        self.history = []

```



### 4.2 克隆语音模型替换

克隆语音模型也可以根据自己需求和克隆好的模型进行替换，具体在`webui.py`的第80行，需要调整一下权重路径，和参考音频，以及参考音频的文本。

```bash
elif voice == "克隆烟嗓音":
    try:
        # 设置 GPT 模型的权重路径
        gpt_path = "GPT_weights权重路径"
        # 设置 SoVITS 模型的权重路径
        sovits_path = "SoVITS_weights权重路径"
        
        # 加载声音克隆模型
        vits.load_model(gpt_path, sovits_path)
        
        # 设置参考音频的路径
        ref_wav_path = "examples/slicer_opt/vocal_output.wav_10.wav_0000846400_0000957760.wav"
        # 设置参考音频的文本
        prompt_text = "你为什么要一次一次的伤我的心啊？"
        
        # 设置要生成音频的文本
        text = answer
        # 设置生成音频文本的语言
        text_language = "中英混合"
        
        # 设置如何切分文本以生成音频
        how_to_cut = "按标点符号切"
        
        # 设置生成音频的保存路径
        save_path = 'answer.wav'
        
        # 使用声音克隆模型生成音频
        vits.predict(ref_wav_path=ref_wav_path,
                     prompt_text=prompt_text,
                     prompt_language="中文",
                     text=text,
                     text_language=text_language,
                     how_to_cut=how_to_cut,
                     save_path=save_path)
        
        # 返回生成的音频路径以及文本
        return 'answer.wav', None, answer
    except Exception as e:
        # 处理异常情况
        gr.Error("无克隆环境或者无克隆模型权重，无法克隆声音", e)
        return None, None, None

```



## 五、交流群问题

有没有什么交流群，暂时没有，因为可能没有时间去管理，如果大家感兴趣我会搞一个，已经搞了一个，大家可以交流学习

大家有什么想法可以在视频下方留言或者私信我，我都会看的，如果交流群过期了，可以加我wx：`pikachu2biubiu`

<img src="docs/QR.jpg#pic_center" style="zoom:50%;" />